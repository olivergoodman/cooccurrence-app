{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import heapq\n",
    "from nltk import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CooccurrenceMatrix:\n",
    "    \"\"\"\n",
    "    corpus        --  text file, declared when object created\n",
    "    data          --  string\n",
    "    sents         --  list of strings, all the sentences in text file (with punctiation)\n",
    "    tokens        --  list of strings, all tokens in text file (with repetitions)\n",
    "    unique_tokens --  list of strings, all unique tokens\n",
    "    num_tokens    --  int, number of unique tokens in text\n",
    "    fdist         --  fdist object\n",
    "    cooc_matrix   --  2D list, initialized to all 0's in prepareCorpus\n",
    "    word_indices  --  dictionary (key=word, value=index in cooc_matrix)\n",
    "    \"\"\"\n",
    "    def __init__(self, c):\n",
    "        self.corpus = c \n",
    "        self.data = \"\"\n",
    "        self.sents = []\n",
    "        self.tokens = []\n",
    "        self.unique_tokens = []\n",
    "        self.num_tokens = 0\n",
    "        self.fdist = None\n",
    "        self.cooc_matrix = None\n",
    "        self.word_indices = {}\n",
    "        \n",
    "    def prepareCorpus(self):\n",
    "        \"\"\"Given a text file, removes punctuation, returns the list of all tokens, list of unique tokens, \n",
    "        list of sentences, the number of unique tokens, and the frequency distribution. \n",
    "        Also initializies cooc_matrix to all 0's with size = num_tokens\"\"\"\n",
    "        with open(self.corpus, 'r') as myfile:\n",
    "            self.data = myfile.read().replace('\\n', '')\n",
    "        self.data = self.data.lower()\n",
    "        data_no_stop = [i for i in self.data.split() if i not in stopwords.words('english')]\n",
    "        self.data = \" \".join(data_no_stop)\n",
    "        self.sents = sent_tokenize(self.data)\n",
    "        self.data = self.removePunctuation(self.data)\n",
    "        self.tokens = word_tokenize(self.data)\n",
    "        self.unique_tokens = set(self.tokens)\n",
    "        self.num_tokens = len(self.unique_tokens)\n",
    "        self.fdist = FreqDist(self.tokens)\n",
    "        self.cooc_matrix = np.zeros((self.num_tokens, self.num_tokens))\n",
    "        self.fillMatrix()\n",
    "        return\n",
    "\n",
    "    def fillMatrix(self):\n",
    "        \"\"\"Fills the cooccurrence matrix\"\"\"\n",
    "        self.findIndices()\n",
    "        for s in self.sents:\n",
    "            s = self.removePunctuation(s)\n",
    "            words = word_tokenize(s)\n",
    "            self.examineSentence(words)\n",
    "        return \n",
    "    \n",
    "    def examineSentence(self, sentence):\n",
    "        \"\"\"Given a sentence (list of words), updates cooccurrence matrix with number of cooccurrences within sentence\n",
    "        Ignores cooccurrences of word with itself\"\"\"\n",
    "        for word1 in sentence:\n",
    "            for word2 in sentence:\n",
    "                index1 = self.word_indices[word1]\n",
    "                index2 = self.word_indices[word2]\n",
    "                if word1 != word2:\n",
    "                    self.cooc_matrix[index1][index2] += 1\n",
    "        return\n",
    "    \n",
    "    def findIndices(self):\n",
    "        \"\"\"Sets word_indices, where each key is a unique token and each value is a index in the cooc_matrix\"\"\"\n",
    "        counter = 0\n",
    "        for t in self.unique_tokens:\n",
    "            self.word_indices[t] = counter\n",
    "            counter += 1\n",
    "        return\n",
    "\n",
    "    def removePunctuation(self, text):\n",
    "        \"\"\"Given a piece of text, removes all punctuation (replacing periods, semicolons, colons with spaces)\"\"\"\n",
    "        text = text.replace(\".\", \" \")\n",
    "        text = text.replace(\";\", \" \")\n",
    "        text = text.replace(\":\", \".\")\n",
    "        text = text.replace(\",\", \"\")\n",
    "        text = text.replace(\"-\", \" \")\n",
    "        exclude = set(string.punctuation)\n",
    "        text = ''.join(ch for ch in text if ch not in exclude)\n",
    "        return text\n",
    "    \n",
    "    def findCooccurrence(self, target_word):\n",
    "        \"\"\"returns the cooccurrences of a given word\"\"\"\n",
    "        if target_word not in self.word_indices:\n",
    "            return \"Target word not in corpus. Try another word.\"\n",
    "        index_target_word = self.word_indices[target_word]\n",
    "        vals = []\n",
    "        top3 = []\n",
    "        max_index = 0\n",
    "        for col in range(self.num_tokens):\n",
    "            if len(top3) > 3:\n",
    "                del(top3[-1])\n",
    "            vals.append(self.cooc_matrix[index_target_word][col])\n",
    "        top3 = heapq.nlargest(3, set(vals)) #number of coocs --> can change top-n\n",
    "        coocs = [] #index of top3 coocs\n",
    "        for i in top3:\n",
    "            for j in range(self.num_tokens):\n",
    "                if self.cooc_matrix[index_target_word][j] == i:\n",
    "                    coocs.append(j)\n",
    "                    break\n",
    "        result = []\n",
    "        for c in coocs:\n",
    "            result.append((list(self.word_indices.keys())[list(self.word_indices.values()).index(c)]))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['america', 'time', 'new']\n"
     ]
    }
   ],
   "source": [
    "# Testing on obama.txt\n",
    "obama = CooccurrenceMatrix('obama.txt')\n",
    "obama.prepareCorpus()\n",
    "print obama.findCooccurrence('change')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['policy', 'president', 'cold']\n"
     ]
    }
   ],
   "source": [
    "# Testing on trump.txt\n",
    "trump = CooccurrenceMatrix('trump.txt')\n",
    "trump.prepareCorpus()\n",
    "print trump.findCooccurrence('war')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TO DO:\n",
    "# input word in system, look up word in matrix and return (n)-most cooccurring words\n",
    "# add a bigger corpus, or put together lots of obama's speeches together \n",
    "# what words to obama use similarly together (maybe use other political figures) \n",
    "# for this word obama uses like this, this other politician uses it like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
